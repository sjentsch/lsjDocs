# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2020, Danielle J. Navarro & David R. Foxcroft. This work is
# licensed under a Creative Commons Attribution-Non Commercial 4.0
# International License.
# This file is distributed under the same license as the Learning statistics
# with jamovi package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Learning statistics with jamovi \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-01-18 19:57+0100\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"

#: ../../lsj/Ch01_WhyStats_2.rst:4
msgid "The curse of belief bias"
msgstr ""

#: ../../lsj/Ch01_WhyStats_2.rst:6
msgid ""
"People are mostly pretty smart. We’re certainly smarter than the other "
"species that we share the planet with (though many people might "
"disagree). Our minds are quite amazing things, and we seem to be capable "
"of the most incredible feats of thought and reason. That doesn’t make us "
"perfect though. And among the many things that psychologists have shown "
"over the years is that we really do find it hard to be neutral, to "
"evaluate evidence impartially and without being swayed by pre-existing "
"biases. A good example of this is the **belief bias effect** in logical "
"reasoning: if you ask people to decide whether a particular argument is "
"logically valid (i.e., conclusion would be true if the premises were "
"true), we tend to be influenced by the believability of the conclusion, "
"even when we shouldn’t. For instance, here’s a valid argument where the "
"conclusion is believable:"
msgstr ""

#: ../../lsj/Ch01_WhyStats_2.rst
msgid "All cigarettes are expensive (Premise 1)"
msgstr ""

#: ../../lsj/Ch01_WhyStats_2.rst
msgid "Some addictive things are inexpensive (Premise 2)"
msgstr ""

#: ../../lsj/Ch01_WhyStats_2.rst
msgid "Therefore, some addictive things are not cigarettes (Conclusion)"
msgstr ""

#: ../../lsj/Ch01_WhyStats_2.rst:24
msgid "And here’s a valid argument where the conclusion is not believable:"
msgstr ""

#: ../../lsj/Ch01_WhyStats_2.rst
msgid "All addictive things are expensive (Premise 1)"
msgstr ""

#: ../../lsj/Ch01_WhyStats_2.rst
msgid "Some cigarettes are inexpensive (Premise 2)"
msgstr ""

#: ../../lsj/Ch01_WhyStats_2.rst
msgid "Therefore, some cigarettes are not addictive (Conclusion)"
msgstr ""

#: ../../lsj/Ch01_WhyStats_2.rst:30
msgid ""
"The logical *structure* of argument #2 is identical to the structure of "
"argument #1, and they’re both valid. However, in the second argument, "
"there are good reasons to think that premise 1 is incorrect, and as a "
"result it’s probably the case that the conclusion is also incorrect. But "
"that’s entirely irrelevant to the topic at hand; an argument is "
"deductively valid if the conclusion is a logical consequence of the "
"premises. That is, a valid argument doesn’t have to involve true "
"statements."
msgstr ""

#: ../../lsj/Ch01_WhyStats_2.rst:39
msgid ""
"On the other hand, here’s an invalid argument that has a believable "
"conclusion:"
msgstr ""

#: ../../lsj/Ch01_WhyStats_2.rst:46
msgid "And finally, an invalid argument with an unbelievable conclusion:"
msgstr ""

#: ../../lsj/Ch01_WhyStats_2.rst:52
#, python-format
msgid ""
"Now, suppose that people really are perfectly able to set aside their "
"pre-existing biases about what is true and what isn’t, and purely "
"evaluate an argument on its logical merits. We’d expect 100% of people to"
" say that the valid arguments are valid, and 0% of people to say that the"
" invalid arguments are valid. So if you ran an experiment looking at "
"this, you’d expect to see data like this:"
msgstr ""

#: ../../lsj/Ch01_WhyStats_2.rst:60 ../../lsj/Ch01_WhyStats_2.rst:80
#: ../../lsj/Ch01_WhyStats_2.rst:92
msgid "conclusion feels true"
msgstr ""

#: ../../lsj/Ch01_WhyStats_2.rst:60 ../../lsj/Ch01_WhyStats_2.rst:80
#: ../../lsj/Ch01_WhyStats_2.rst:92
msgid "conclusion feels false"
msgstr ""

#: ../../lsj/Ch01_WhyStats_2.rst:62 ../../lsj/Ch01_WhyStats_2.rst:82
#: ../../lsj/Ch01_WhyStats_2.rst:94
msgid "argument is valid"
msgstr ""

#: ../../lsj/Ch01_WhyStats_2.rst:62
#, python-format
msgid "100% say “valid”"
msgstr ""

#: ../../lsj/Ch01_WhyStats_2.rst:64 ../../lsj/Ch01_WhyStats_2.rst:84
#: ../../lsj/Ch01_WhyStats_2.rst:96
msgid "argument is invalid"
msgstr ""

#: ../../lsj/Ch01_WhyStats_2.rst:64
#, python-format
msgid "0% say “valid”"
msgstr ""

#: ../../lsj/Ch01_WhyStats_2.rst:67
msgid ""
"If the psychological data looked like this (or even a good approximation "
"to this), we might feel safe in just trusting our gut instincts. That is,"
" it’d be perfectly okay just to let scientists evaluate data based on "
"their common sense, and not bother with all this murky statistics stuff. "
"However, you guys have taken psych classes, and by now you probably know "
"where this is going."
msgstr ""

#: ../../lsj/Ch01_WhyStats_2.rst:74
msgid ""
"In a classic study, `Evans et al. (1983) <References.html#evans-1983>`__ "
"ran an experiment looking at exactly this. What they found is that when "
"pre-existing biases (i.e., beliefs) were in agreement with the structure "
"of the data, everything went the way you’d hope:"
msgstr ""

#: ../../lsj/Ch01_WhyStats_2.rst:82 ../../lsj/Ch01_WhyStats_2.rst:94
#, python-format
msgid "92% say “valid”"
msgstr ""

#: ../../lsj/Ch01_WhyStats_2.rst:84 ../../lsj/Ch01_WhyStats_2.rst:96
#, python-format
msgid "8% say “valid”"
msgstr ""

#: ../../lsj/Ch01_WhyStats_2.rst:87
msgid ""
"Not perfect, but that’s pretty good. But look what happens when our "
"intuitive feelings about the truth of the conclusion run against the "
"logical structure of the argument:"
msgstr ""

#: ../../lsj/Ch01_WhyStats_2.rst:94
#, python-format
msgid "**46% say “valid”**"
msgstr ""

#: ../../lsj/Ch01_WhyStats_2.rst:96
#, python-format
msgid "**92% say “valid”**"
msgstr ""

#: ../../lsj/Ch01_WhyStats_2.rst:99
#, python-format
msgid ""
"Oh dear, that’s not as good. Apparently, when people are presented with a"
" strong argument that contradicts our pre-existing beliefs, we find it "
"pretty hard to even perceive it to be a strong argument (people only did "
"so 46% of the time). Even worse, when people are presented with a weak "
"argument that agrees with our pre-existing biases, almost no-one can see "
"that the argument is weak (people got that one wrong 92% of the time!).\\"
" [#]_"
msgstr ""

#: ../../lsj/Ch01_WhyStats_2.rst:107
#, python-format
msgid ""
"If you think about it, it’s not as if these data are horribly damning. "
"Overall, people did do better than chance at compensating for their prior"
" biases, since about 60% of people’s judgements were correct (you’d "
"expect 50% by chance). Even so, if you were a professional “evaluator of "
"evidence”, and someone came along and offered you a magic tool that "
"improves your chances of making the right decision from 60% to (say) 95%,"
" you’d probably jump at it, right? Of course you would. Thankfully, we "
"actually do have a tool that can do this. But it’s not magic, it’s "
"statistics. So that’s reason #1 why scientists love statistics. It’s just"
" *too easy* for us to “believe what we want to believe”. So instead, if "
"we want to “believe in the data”, we’re going to need a bit of help to "
"keep our personal biases under control. That’s what statistics does, it "
"helps keep us honest."
msgstr ""

#: ../../lsj/Ch01_WhyStats_2.rst:124
#, python-format
msgid ""
"In my more cynical moments I feel like this fact alone explains 95% of "
"what I read on the internet."
msgstr ""

