# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2020, Danielle J. Navarro & David R. Foxcroft. This work is
# licensed under a Creative Commons Attribution-Non Commercial 4.0
# International License.
# This file is distributed under the same license as the Learning statistics
# with jamovi package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Learning statistics with jamovi \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-07-14 12:32+0200\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"

#: ../../lsj/Ch11_tTest_09.rst:4
msgid "Testing non-normal data with Wilcoxon tests"
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:6
msgid ""
"Okay, suppose your data turn out to be pretty substantially non-normal, "
"but you still want to run something like a *t*-test? This situation "
"occurs a lot in real life. For the AFL winning margins data, for "
"instance, the Shapiro-Wilk test made it very clear that the normality "
"assumption is violated. This is the situation where you want to use "
"Wilcoxon tests."
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:13
msgid ""
"Like the *t*-test, the Wilcoxon test comes in two forms, one-sample and "
"two-sample, and they’re used in more or less the exact same situations as"
" the corresponding *t*-tests. Unlike the *t*-test, the Wilcoxon test "
"doesn’t assume normality, which is nice. In fact, they don’t make any "
"assumptions about what kind of distribution is involved. In statistical "
"jargon, this makes them **nonparametric tests**. While avoiding the "
"normality assumption is nice, there’s a drawback: the Wilcoxon test is "
"usually less powerful than the *t*-test (i.e., higher Type II error "
"rate). I won’t discuss the Wilcoxon tests in as much detail as the "
"*t*-tests, but I’ll give you a brief overview."
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:26
msgid "Two sample Mann-Whitney U test"
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:28
msgid ""
"I’ll start by describing the **Mann-Whitney U test**, since it’s actually"
" simpler than the one sample version. Suppose we’re looking at the scores"
" of 10 people on some test. Since my imagination has now failed me "
"completely, let’s pretend it’s a “test of awesomeness” and there are two "
"groups of people, “A” and “B”. I’m curious to know which group is more "
"awesome. The data are included in the ``awesome`` dataset, and there are "
"two variables apart from the usual ``ID`` variable: ``scores`` and "
"``group``."
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:37
msgid ""
"As long as there are no ties (i.e., people with the exact same "
"awesomeness score) then the test that we want to do is surprisingly "
"simple. All we have to do is construct a table that compares every "
"observation in group A against every observation in group B. Whenever the"
" group A datum is larger, we place a check mark in the table:"
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:44
msgid "Group B"
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:46
msgid "14.5"
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:46
msgid "10.4"
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:46
msgid "12.4"
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:46
msgid "11.7"
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:46
msgid "13.0"
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:52
msgid "Group A"
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:48
msgid "6.4"
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:50
msgid "10.7"
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:50 ../../lsj/Ch11_tTest_09.rst:52
#: ../../lsj/Ch11_tTest_09.rst:95 ../../lsj/Ch11_tTest_09.rst:97
msgid "✓"
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:52
msgid "11.9"
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:54
msgid "7.3"
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:56
msgid "10.0"
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:59
msgid ""
"We then count up the number of checkmarks. This is our test statistic, "
"*W*.\\ [#]_ The actual sampling distribution for *W* is somewhat "
"complicated, and I’ll skip the details. For our purposes, it’s sufficient"
" to note that the interpretation of *W* is qualitatively the same as the "
"interpretation of *t* or *z*. That is, if we want a two-sided test then "
"we reject the null hypothesis when *W* is very large or very small, but "
"if we have a directional (i.e., one-sided) hypothesis then we only use "
"one or the other."
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:67
msgid ""
"In jamovi, if we run an ``Independent Samples t-Test`` with ``scores`` as"
" the dependent variable. and ``group`` as the grouping variable, and then"
" under the options for ``Tests`` check the option for ``Mann-Whitney U``,"
" we will get results showing that U = 3 (i.e., the same number of check "
"marks as shown above), and a p-value = 0.05556."
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:74
msgid "One sample Wilcoxon test"
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:76
msgid ""
"What about the **one sample Wilcoxon test** (or equivalently, the paired "
"samples Wilcoxon test)? Suppose I’m interested in finding out whether "
"taking a statistics class has any effect on the happiness of students. My"
" data is in the ``happiness.csv`` file. What I’ve measured here is the "
"happiness of each student ``before`` taking the class and ``after`` "
"taking the class, and the ``change`` score is the difference between the "
"two. Just like we saw with the *t*-test, there’s no fundamental "
"difference between doing a paired-samples test using ``before`` and "
"``after``, versus doing a one-sample test using the ``change`` scores. As"
" before, the simplest way to think about the test is to construct a "
"tabulation. The way to do it this time is to take those change scores "
"that are positive differences, and tabulate them against all the complete"
" sample. What you end up with is a table that looks like this:"
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:91
msgid "all differences"
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:93
msgid "-24"
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:93
msgid "-14"
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:93
msgid "-10"
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:93
msgid "7"
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:93
msgid "-6"
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:93
msgid "-38"
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:93
msgid "2"
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:93
msgid "-35"
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:93
msgid "-30"
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:93
msgid "5"
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:96
msgid "positive differences"
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:95
msgid "7 2 5"
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:95
msgid "✓ ✓ ✓"
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:100
msgid ""
"Counting up the tick marks this time we get a test statistic of *W* = 7. "
"As before, if our test is two-sided, then we reject the null hypothesis "
"when *W* is very large or very small. As far as running it in jamovi "
"goes, it’s pretty much what you’d expect. For the one-sample version, you"
" specify the ``Wilcoxon rank`` option under ``Tests`` in the ``One Sample"
" *t*-Test`` analysis panel.This gives you Wilcoxon *W* = 7, *p*-value = "
"0.03711. As this shows, we have a significant effect. Evidently, taking a"
" statistics class does have an effect on your happiness. Switching to a "
"paired samples version of the test won’t give us a different answer, of "
"course; see :numref:`fig-ttest_nonparametric`."
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:117
msgid "Results for one sample and paired sample Wilcoxon non-parametric tests"
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:117
msgid ""
"jamovi screen showing results for one sample and paired sample Wilcoxon "
"non-parametric tests"
msgstr ""

#: ../../lsj/Ch11_tTest_09.rst:125
msgid ""
"Actually, there are two different versions of the test statistic that "
"differ from each other by a constant value. The version that I’ve "
"described is the one that jamovi calculates."
msgstr ""

